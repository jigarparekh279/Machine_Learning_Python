{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TensorFlow for Deep Learning - Processing Sequences Using RNNs and CNNs\n",
    "\n",
    "Credits:\n",
    "- [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)\n",
    "- [Udacity Deep Learning Nanodegree](https://www.udacity.com/course/deep-learning-nanodegree--nd101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [RNN Example](https://youtu.be/MDLk3fhpTx0)\n",
    "- [Implementing a Char-RNN](https://youtu.be/MMtgZXzFB10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Recurrent Neurons and Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "A recurrent neural network looks very much like a feedforward neural network, except it also has connections pointing backward. Let's look at the simplest possible RNN, composed of one neuron receiving inputs, producing an output, and sending that output back to itself. At each\n",
    "time step t (also called a frame), this recurrent neuron receives the inputs $\\mathbf{x}_{(t)} $ as well as its own output from the previous time step, $\\mathbf{y}_{(t-1)} $. Since there is no previous output at the first time step, it is generally set to 0. \n",
    "\n",
    "<img src=\"images/RNN2.png\" align=\"center\" width=\"500\"/>\n",
    "\n",
    "Each recurrent neuron has two sets of weights: one for the inputs $\\mathbf{x}_{(t)} $  and the other for the outputs of the previous time step, $\\mathbf{y}_{(t-1)} $. Let's call these weight vectors $\\mathbf{w}_x$ and $\\mathbf{w}_y$. If we consider the whole recurrent layer instead of just one recurrent neuron, we can place all the weight vectors in two weight matrices, $\\mathbf{W}_x$ and $\\mathbf{W}_y$. The output vector of the whole recurrent layer for a single instance can then be computed as:\n",
    "\n",
    "$ \\mathbf{y}_{(t)} = \\phi (\\mathbf{W}_x^T \\mathbf{x}_{(t)}  + \\mathbf{W}_y^T \\mathbf{y}_{(t-1)}  + \\mathbf{b}) $\n",
    "\n",
    "Just as with feedforward neural networks, we can compute a recurrent layer's output in one shot for a whole mini-batch by placing all the inputs at time step t in an input matrix $\\mathbf{X}_t$:\n",
    "\n",
    "<img src=\"images/RNN3.png\" align=\"center\" width=\"500\"/>\n",
    "<img src=\"images/RNN4.png\" align=\"center\" width=\"500\"/>\n",
    "\n",
    "- [Recurrent Neural Network - Part a](https://youtu.be/ofbnDxGSUcg)\n",
    "- [Recurrent Neural Network - Part b](https://youtu.be/wsif3p5t7CI)\n",
    "- [RNN Unfolded](https://youtu.be/xLIA_PTWXog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Memory Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the output of a recurrent neuron at time step t is a function of all the inputs from previous time steps, you could say it has a form of _memory_. \n",
    "- A part of a neural network that preserves some state across time steps is called a _memory cell_ (or simply a _cell_). A single recurrent neuron, or a layer of recurrent neurons, is a very basic cell, capable of learning only short patterns (typically about 10 steps long, but this varies depending on the task).\n",
    "\n",
    "    <img src=\"images/RNN5.png\" align=\"center\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input and Output Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _sequence-to-sequence network_ is useful for predicting time series such as stock prices: you feed it the prices over the last N days, and it must output the prices shifted by one day into the future (i.e., from N-1 days ago to tomorrow).\n",
    "- _sequence-to-vector network_ is useful for example - feed the network a sequence of words corresponding to a movie review, and the network would output a sentiment score.\n",
    "- _vector-to-sequence network_ where the input could be an image (or the output of a CNN), and the output could be a caption for that image.\n",
    "- _sequence-to-vector network_ (_encoder_) followed by _vector-to-sequence network_ (_decoder_) could be used for translating a sentence from one language to another. You would feed the network a sentence in one language, the encoder would convert this sentence into a single vector representation, and then the decoder would decode this vector into a sentence in another language\n",
    "\n",
    "    <img src=\"images/RNN6.png\" align=\"center\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deep RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/RNN7.png\" align=\"center\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training RNN vis BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Backpropagation through Time - Part a](https://youtu.be/eE2L3-2wKac)\n",
    "- [Backpropagation through Time - Part b](https://youtu.be/bUU9BEQw0IA)\n",
    "- [Backpropagation through Time - Part c](https://youtu.be/bUU9BEQw0IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Forecasting a Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we are using a time series generated by the\n",
    "generate_time_series() function, shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps): \n",
    "    import numpy as np\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1) \n",
    "    time = np.linspace(0, 1, n_steps) \n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1 \n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2 \n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise \n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates as many time series as requested (via the batch_size\n",
    "argument), each of length n_steps, and there is just one value per time step\n",
    "in each series (i.e., all series are univariate). The function returns a NumPy\n",
    "array of shape [batch size, time steps, 1], where each series is the sum of\n",
    "two sine waves of fixed amplitudes but random frequencies and phases,\n",
    "plus a bit of noise.\n",
    "\n",
    "**NOTE**: When dealing with time series (and other types of sequences such as sentences), the\n",
    "input features are generally represented as 3D arrays of shape [batch size, time steps,\n",
    "dimensionality], where dimensionality is 1 for univariate time series and more for\n",
    "multivariate time series.\n",
    "\n",
    "Train, Valid, Test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33758703],\n",
       "       [-0.01265792],\n",
       "       [ 0.5252002 ],\n",
       "       ...,\n",
       "       [ 0.5760455 ],\n",
       "       [ 0.6067221 ],\n",
       "       [-0.25718474]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Baseline Metrics (Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) The simplest approach is to predict the last value in each series. This is called _naive forecasting_, and it is sometimes surprisingly difficult to outperform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 16:23:52.177070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38457 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:31:00.0, compute capability: 8.0\n",
      "2021-11-24 16:23:52.179238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38457 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:32:00.0, compute capability: 8.0\n",
      "2021-11-24 16:23:52.180955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38457 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:ca:00.0, compute capability: 8.0\n",
      "2021-11-24 16:23:52.182647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38457 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:e3:00.0, compute capability: 8.0\n",
      "2021-11-24 16:23:52.182895: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.020387158"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y_pred = X_valid[:, -1]\n",
    "np.mean(tf.keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Another simple approach is to use a fully connected network. Let's just use a simple Linear Regression model so that each prediction will\n",
    "be a linear combination of the values in the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 16:23:53.044824: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 1s 702us/step - loss: 0.1253\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 694us/step - loss: 0.0334\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 685us/step - loss: 0.0162\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 687us/step - loss: 0.0102\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 682us/step - loss: 0.0078\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 679us/step - loss: 0.0067\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 678us/step - loss: 0.0060\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 681us/step - loss: 0.0056\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 682us/step - loss: 0.0052\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 692us/step - loss: 0.0050\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 685us/step - loss: 0.0047\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 685us/step - loss: 0.0045\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 687us/step - loss: 0.0044\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 686us/step - loss: 0.0043\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 681us/step - loss: 0.0041\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 684us/step - loss: 0.0041\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 684us/step - loss: 0.0040\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 683us/step - loss: 0.0039\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 680us/step - loss: 0.0038\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 697us/step - loss: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1489b11d6970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.Flatten(input_shape=[50, 1]), \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 526us/step - loss: 0.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0035277805291116238"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Implementing a Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([ \n",
    "  tf.keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "    # recurrent-neurons, [steps, features]\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's really the simplest RNN you can build. It just contains a single layer, with a single neuron. We do not need to specify\n",
    "the length of the input sequences (unlike in the previous model), since a recurrent neural network can process any number of time steps (this is why we set the first input dimension to None). By default, the SimpleRNN layer\n",
    "uses the hyperbolic tangent activation function. It works exactly as we saw\n",
    "earlier: the initial state $h_{init}$ is set to 0, and it is passed to a single recurrent\n",
    "neuron, along with the value of the first time step, $x_{(0)}$. The neuron\n",
    "computes a weighted sum of these values and applies the hyperbolic tangent\n",
    "activation function to the result, and this gives the first output, $y_0$ . In a\n",
    "simple RNN, this output is also the new state $h_0$. This new state is passed to\n",
    "the same recurrent neuron along with the next input value, $x_{(1)}$ , and the\n",
    "process is repeated until the last time step. Then the layer just outputs the\n",
    "last value, $y_{49}$ . All of this is performed simultaneously for every time series.\n",
    "\n",
    "**NOTE**: By default, recurrent layers in Keras only return the final output. To make them return one output per time step, you must set ```return_sequences=True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.3007\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.1865\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.0925\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0473\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.0340\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0300\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 16ms/step - loss: 0.0278\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0260\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0243\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0227\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0213\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0201\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0189\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0179\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0169\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0161\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 15ms/step - loss: 0.0153\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0147\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0140\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 4s 16ms/step - loss: 0.0135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1489b10653d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.013325328007340431"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is better than the naive approach but it does not beat a simple linear model. Note that for each neuron, a linear model has one parameter per input and per time step, plus a bias term (in the simple linear model we used, that's a\n",
    "total of **51** parameters). In contrast, for each recurrent neuron in a simple\n",
    "RNN, there is just one parameter per input and per hidden state dimension\n",
    "(in a simple RNN, that's just the number of recurrent neurons in the layer),\n",
    "plus a bias term. In this simple RNN, that's a total of just **3** parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Deep RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a deep RNN with tf.keras is quite simple: just stack recurrent\n",
    "layers. In this example, we use three SimpleRNN layers (but we could add\n",
    "any other type of recurrent layer, such as an LSTM layer or a GRU layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# seq-to-seq network\n",
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]), \n",
    "    tf.keras.layers.SimpleRNN(20, return_sequences=True), \n",
    "    tf.keras.layers.SimpleRNN(1)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: Make sure to set return_sequences=True for all recurrent layers (except the last one, if you only care about the last output). If you don't, they will output a 2D array (containing only the output of the last time step) instead of a 3D array (containing outputs for all time steps), and the next recurrent layer will complain that you are not feeding it sequences in the expected 3D format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the last layer is not ideal: it must have a single unit because we\n",
    "want to forecast a univariate time series, and this means we must have a\n",
    "single output value per time step. However, having a single unit means that\n",
    "the hidden state is just a single number. That's really not much, and it's\n",
    "probably not that useful; presumably, the RNN will mostly use the hidden\n",
    "states of the other recurrent layers to carry over all the information it needs\n",
    "from time step to time step, and it will not use the final layer's hidden state\n",
    "very much. Moreover, since a SimpleRNN layer uses the tanh activation\n",
    "function by default, the predicted values must lie within the range -1 to 1.\n",
    "But what if you want to use another activation function? For both these\n",
    "reasons, it might be preferable to replace the output layer with a Dense\n",
    "layer: it would run slightly faster, the accuracy would be roughly the same,\n",
    "and it would allow us to choose any output activation function we want. If\n",
    "you make this change, also make sure to remove ```return_sequences=True```\n",
    "from the second (now last) recurrent layer (bcoz we now have a _seq-to-vec_ network):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 20)          440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# seq-to-vec network\n",
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]), \n",
    "    tf.keras.layers.SimpleRNN(20), \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary() # [features*n_neurons + n_neurons*n_neurons + bias] = [1x20 + 20x20 + 20], [20x20 + 20x20 + 20], [20x1 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  5/219 [..............................] - ETA: 7s - loss: 0.4569 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 16:25:09.933528: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 10s 37ms/step - loss: 0.0389\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0052\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0041\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0037\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0036\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0035\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.0034\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0034\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0034\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0033\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0032\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0031\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0032\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0031\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0031\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0030\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0030\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0030\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0030\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1489b0f40df0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 7ms/step - loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0027229059487581253"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Forecasting Several Time Steps Ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first option is to use the model we already trained, make it predict the\n",
    "next value, then add that value to the inputs (acting as if this predicted value\n",
    "had actually occurred), and use the model again to predict the following\n",
    "value, and so on. As you might expect, the prediction for the next step will usually be more\n",
    "accurate than the predictions for later time steps, since the errors might\n",
    "accumulate.\n",
    "- The second option is to train an RNN to predict all 10 next values at once.\n",
    "We can still use a _sequence-to-vector_ model, but it will output 10 values\n",
    "instead of 1.\n",
    "- We can still do better: indeed,\n",
    "instead of training the model to forecast the next 10 values only at the very\n",
    "last time step, we can train it to forecast the next 10 values at each and\n",
    "every time step. In other words, we can turn this _sequence-to-vector_ RNN\n",
    "into a _sequence-to-sequence_ RNN. The advantage of this technique is that\n",
    "the loss will contain a term for the output of the RNN at each and every\n",
    "time step, not just the output at the last time step. This means there will be\n",
    "many more error gradients flowing through the model, and they won??t have\n",
    "to flow only through time; they will also flow from the output of each time\n",
    "step. This will both stabilize and speed up training. To be clear, at time step 0 the model will output a vector containing the\n",
    "forecasts for time steps 1 to 10, then at time step 1 the model will forecast\n",
    "time steps 2 to 11, and so on. So each target must be a sequence of the same\n",
    "length as the input sequence, containing a 10-dimensional vector at each\n",
    "step.\n",
    "\n",
    "    **NOTE**: It may be surprising that the targets will contain values that appear in the inputs (there is\n",
    "a lot of overlap between X_train and Y_train). Isn't that cheating? Fortunately, not at\n",
    "all: at each time step, the model only knows about past time steps, so it cannot look\n",
    "ahead. It is said to be a _causal_ model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = generate_time_series(10000, n_steps + 10)\n",
    "Y = np.empty((10000, n_steps, 10)) # each target is a sequence of 10D vectors\n",
    "for step_ahead in range(1, 10 + 1): \n",
    "    Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "X_train, Y_train = series[:7000, :n_steps], Y[:7000]\n",
    "X_valid, Y_valid = series[7000:9000, :n_steps], Y[7000:9000]\n",
    "X_test, Y_test = series[9000:, :n_steps], Y[9000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn the model into a sequence-to-sequence model, we must set\n",
    "return_sequences=True in all recurrent layers (even the last one), and we\n",
    "must apply the output Dense layer at every time step. Keras offers a\n",
    "TimeDistributed layer for this very purpose: it wraps any layer (e.g., a\n",
    "Dense layer) and applies it at every time step of its input sequence. It does\n",
    "this efficiently, by reshaping the inputs so that each time step is treated as a\n",
    "separate instance (i.e., it reshapes the inputs from [batch size, time steps,\n",
    "input dimensions] to [batch size ×? time steps, input dimensions]; in this\n",
    "example, the number of input dimensions is 20 because the previous\n",
    "SimpleRNN layer has 20 units), then it runs the Dense layer, and finally it\n",
    "reshapes the outputs back to sequences (i.e., it reshapes the outputs from\n",
    "[batch size ×? time steps, output dimensions] to [batch size, time steps,\n",
    "output dimensions]; in this example the number of output dimensions is 10,\n",
    "since the Dense layer has 10 units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, None, 20)          440       \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, None, 20)          820       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 10)          210       \n",
      "=================================================================\n",
      "Total params: 1,470\n",
      "Trainable params: 1,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# seq-to-seq network\n",
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]), \n",
    "    tf.keras.layers.SimpleRNN(20, return_sequences=True), \n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All outputs are needed during training, but only the output at the last time\n",
    "step is useful for predictions and for evaluation. So although we will rely on\n",
    "the MSE over all the outputs for training, we will use a custom metric for\n",
    "evaluation, to only compute the MSE over the output at the last time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred): \n",
    "    return tf.keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/arch/Centos8/EB_production/2021/software/TensorFlow/2.6.0-foss-2021a-CUDA-11.3.1/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 10s 38ms/step - loss: 0.0517 - last_time_step_mse: 0.0422\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0368 - last_time_step_mse: 0.0248\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0311 - last_time_step_mse: 0.0189\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0281 - last_time_step_mse: 0.0162\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.0255 - last_time_step_mse: 0.0132\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0232 - last_time_step_mse: 0.0107\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0215 - last_time_step_mse: 0.0090\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0205 - last_time_step_mse: 0.0081\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0205 - last_time_step_mse: 0.0084\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0199 - last_time_step_mse: 0.0077\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0194 - last_time_step_mse: 0.0074\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0192 - last_time_step_mse: 0.0072\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0192 - last_time_step_mse: 0.0073\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0194 - last_time_step_mse: 0.0075\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0191 - last_time_step_mse: 0.0071\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 8s 38ms/step - loss: 0.0189 - last_time_step_mse: 0.0070\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0189 - last_time_step_mse: 0.0071\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0183 - last_time_step_mse: 0.0065\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 8s 34ms/step - loss: 0.0183 - last_time_step_mse: 0.0065\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0184 - last_time_step_mse: 0.0066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1489b0d46430>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 7ms/step - loss: 0.0187 - last_time_step_mse: 0.0069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01866469345986843, 0.006900131236761808]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Trend and Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other models to forecast time series, such as _weighted\n",
    "moving average_ models or _autoregressive integrated moving average_\n",
    "(ARIMA) models. Some of them require you to first remove the trend\n",
    "and seasonality. For example, if you are studying the number of active\n",
    "users on your website, and it is growing by 10% every month, you\n",
    "would have to remove this trend from the time series. Once the model is\n",
    "trained and starts making predictions, you would have to add the trend\n",
    "back to get the final predictions. Similarly, if you are trying to predict\n",
    "the amount of sunscreen lotion sold every month, you will probably\n",
    "observe strong seasonality: since it sells well every summer, a similar\n",
    "pattern will be repeated every year. You would have to remove this\n",
    "seasonality from the time series, for example by computing the\n",
    "difference between the value at each time step and the value one year\n",
    "earlier (this technique is called _differencing_). Again, after the model is\n",
    "trained and makes predictions, you would have to add the seasonal\n",
    "pattern back to get the final predictions.\n",
    "When using RNNs, it is generally not necessary to do all this, but it\n",
    "may improve performance in some cases, since the model will not have\n",
    "to learn the trend or the seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Handling Long Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple RNNs can be quite good at forecasting time series or handling other\n",
    "kinds of sequences, but they do not perform as well on long time series or\n",
    "sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Fighting the Unstable Gradients Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [RNN Vanishing Gradient --> LSTM](https://youtu.be/nXP0oGGRrO8)\n",
    "\n",
    "- Why not _ReLU_ activation function?: Many of the tricks we used in deep nets to alleviate the unstable gradients\n",
    "problem can also be used for RNNs: good parameter initialization, faster\n",
    "optimizers, dropout, and so on. However, nonsaturating activation functions\n",
    "(e.g., ReLU) may not help as much here; in fact, they may actually lead the\n",
    "RNN to be even more unstable during training. Why? Well, suppose\n",
    "Gradient Descent updates the weights in a way that increases the outputs\n",
    "slightly at the first time step. Because the same weights are used at every\n",
    "time step, the outputs at the second time step may also be slightly increased,\n",
    "and those at the third, and so on until the outputs explode -- and a\n",
    "nonsaturating activation function does not prevent that. You can reduce this\n",
    "risk by using a smaller learning rate, but you can also simply use a\n",
    "saturating activation function like the hyperbolic tangent (this explains why\n",
    "it is the default). In much the same way, the gradients themselves can\n",
    "explode. If you notice that training is unstable, you may want to monitor the\n",
    "size of the gradients (e.g., using TensorBoard) and perhaps use Gradient\n",
    "Clipping. \n",
    "- _Layer Normalization_: Batch Normalization cannot be used as efficiently with RNNs as\n",
    "with deep feedforward nets. In fact, you cannot use it between time steps,\n",
    "only between recurrent layers. Another form of normalization often works \n",
    "better with RNNs: Layer Normalization. It is very similar to Batch Normalization, but instead of normalizing\n",
    "across the batch dimension, it normalizes across the features dimension.\n",
    "One advantage is that it can compute the required statistics on the fly, at\n",
    "each time step, independently for each instance. This also means that it\n",
    "behaves the same way during training and testing (as opposed to BN), and it\n",
    "does not need to use exponential moving averages to estimate the feature\n",
    "statistics across all instances in the training set. Like BN, Layer\n",
    "Normalization learns a scale and an offset parameter for each input. In an\n",
    "RNN, it is typically used right after the linear combination of the inputs and\n",
    "the hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(tf.keras.layers.Layer): \n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs): \n",
    "        super().__init__(**kwargs) \n",
    "        self.state_size = units \n",
    "        self.output_size = units \n",
    "        self.simple_rnn_cell = tf.keras.layers.SimpleRNNCell(units, activation=None) \n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization() \n",
    "        self.activation = tf.keras.activations.get(activation) \n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states) \n",
    "        norm_outputs = self.activation(self.layer_norm(outputs)) \n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LNSimpleRNNCell class inherits\n",
    "from the keras.layers.Layer class, just like any custom layer. The\n",
    "constructor takes the number of units and the desired activation function,\n",
    "and it sets the state_size and output_size attributes, then creates a\n",
    "SimpleRNNCell with no activation function (because we want to perform\n",
    "Layer Normalization after the linear operation but before the activation\n",
    "function). Then the constructor creates the LayerNormalization layer, and\n",
    "finally it fetches the desired activation function. The call() method starts\n",
    "by applying the simple RNN cell, which computes a linear combination of\n",
    "the current inputs and the previous hidden states, and it returns the result\n",
    "twice (indeed, in a SimpleRNNCell, the outputs are just equal to the hidden\n",
    "states: in other words, new_states[0] is equal to outputs, so we can\n",
    "safely ignore new_states in the rest of the call() method). Next, the\n",
    "call() method applies Layer Normalization, followed by the activation\n",
    "function. Finally, it returns the outputs twice (once as the outputs, and once\n",
    "as the new hidden states)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn (RNN)                    (None, None, 20)          480       \n",
      "_________________________________________________________________\n",
      "rnn_1 (RNN)                  (None, None, 20)          860       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 10)          210       \n",
      "=================================================================\n",
      "Total params: 1,550\n",
      "Trainable params: 1,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True, \n",
    "                     input_shape=[None, 1]), \n",
    "    tf.keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True), \n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All recurrent layers (except for\n",
    "keras.layers.RNN) and all cells provided by Keras have a dropout\n",
    "hyperparameter and a recurrent_dropout hyperparameter: the former\n",
    "defines the dropout rate to apply to the inputs (at each time step), and the\n",
    "latter defines the dropout rate for the hidden states (also at each time step).\n",
    "No need to create a custom cell to apply dropout at each time step in an\n",
    "RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/219 [..............................] - ETA: 14:28 - loss: 0.7059 - last_time_step_mse: 0.6944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 16:30:37.367592: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 23s 87ms/step - loss: 0.0713 - last_time_step_mse: 0.0613\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 19s 87ms/step - loss: 0.0423 - last_time_step_mse: 0.0330\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0331 - last_time_step_mse: 0.0226\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 19s 87ms/step - loss: 0.0289 - last_time_step_mse: 0.0181\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 19s 87ms/step - loss: 0.0264 - last_time_step_mse: 0.0154\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 18s 84ms/step - loss: 0.0255 - last_time_step_mse: 0.0143\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0238 - last_time_step_mse: 0.0124\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 19s 85ms/step - loss: 0.0221 - last_time_step_mse: 0.0102\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0211 - last_time_step_mse: 0.0090\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0204 - last_time_step_mse: 0.0083\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0198 - last_time_step_mse: 0.0080\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 19s 87ms/step - loss: 0.0196 - last_time_step_mse: 0.0079\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0188 - last_time_step_mse: 0.0070\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 19s 85ms/step - loss: 0.0187 - last_time_step_mse: 0.0071\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0184 - last_time_step_mse: 0.0068\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 19s 85ms/step - loss: 0.0184 - last_time_step_mse: 0.0068\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0182 - last_time_step_mse: 0.0069\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0177 - last_time_step_mse: 0.0063\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0176 - last_time_step_mse: 0.0063\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 19s 86ms/step - loss: 0.0175 - last_time_step_mse: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1489b0ced370>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 13ms/step - loss: 0.0184 - last_time_step_mse: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.018381061032414436, 0.007873216643929482]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tackling the Short-Term Memory Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the transformations that the data goes through when traversing an\n",
    "RNN, some information is lost at each time step. After a while, the RNN's\n",
    "state contains virtually no trace of the first inputs. o tackle\n",
    "this problem, various types of cells with long-term memory have been\n",
    "introduced. They have proven so successful that the basic cells are not used\n",
    "much anymore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The _Long Short-Term Memory_ (LSTM) Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 20)          1760      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 20)          3280      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 10)          210       \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]), \n",
    "    tf.keras.layers.LSTM(20, return_sequences=True), \n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 5s 4ms/step - loss: 0.0480 - last_time_step_mse: 0.0338\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0280 - last_time_step_mse: 0.0129\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0228 - last_time_step_mse: 0.0075\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0194 - last_time_step_mse: 0.0050\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0178 - last_time_step_mse: 0.0044\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0168 - last_time_step_mse: 0.0042\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0161 - last_time_step_mse: 0.0040\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0155 - last_time_step_mse: 0.0037\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0152 - last_time_step_mse: 0.0037\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0147 - last_time_step_mse: 0.0035\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0144 - last_time_step_mse: 0.0033\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0141 - last_time_step_mse: 0.0032\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0139 - last_time_step_mse: 0.0032\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0138 - last_time_step_mse: 0.0032\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0136 - last_time_step_mse: 0.0030\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0136 - last_time_step_mse: 0.0030\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0135 - last_time_step_mse: 0.0030\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0135 - last_time_step_mse: 0.0030\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0133 - last_time_step_mse: 0.0029\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0132 - last_time_step_mse: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147f9c804a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 2ms/step - loss: 0.0131 - last_time_step_mse: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013086429797112942, 0.002533094258978963]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [LSTM Basics](https://youtu.be/gjb68a4XsqE)\n",
    "- [The Forget Gate](https://youtu.be/iWxpfxLUPSU)\n",
    "- [The Input/Learn Gate](https://youtu.be/aVHVI7ovbHY)\n",
    "- [The Remember Gate](https://youtu.be/0qlm86HaXuU)\n",
    "- [The Output/Use Gate](https://youtu.be/5Ifolm1jTdY)\n",
    "- [Putting it All Together](https://youtu.be/IF8FlKW-Zo0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/RNN9.png\" align=\"center\" width=\"500\"/>\n",
    "<img src=\"images/RNN8.png\" align=\"center\" width=\"500\"/>\n",
    "\n",
    "As the long-term state $\\mathbf{c}_{(t-1)}$ traverses the network from left to right, you can see that it first goes through a _forget gate_, dropping some memories, and then it adds some new memories via the addition operation (which adds the memories that were selected by an _input gate_) The result $\\mathbf{c}_{(t)}$ is sent straight out, without any further transformation. So, at each time step, some memories are dropped and some memories are added. Moreover, after the addition operation, the long-term state is copied and passed through the tanh function, and then the result is filtered by the _output gate_. This produces the short-term state $\\mathbf{h}_{(t)}$ (which is equal to the cell's output for this\n",
    "time step, $\\mathbf{y}_{(t)}$).\n",
    "\n",
    "<img src=\"images/RNN10.png\" align=\"center\" width=\"500\"/>\n",
    "\n",
    "In short, an LSTM cell can learn to recognize an important input (that's the\n",
    "role of the input gate), store it in the long-term state, preserve it for as long\n",
    "as it is needed (that??s the role of the forget gate), and extract it whenever it\n",
    "is needed. This explains why these cells have been amazingly successful at\n",
    "capturing long-term patterns in time series, long texts, audio recordings, and\n",
    "more.\n",
    "\n",
    "<img src=\"images/RNN11.png\" align=\"center\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The _Gated Recurrent Unit_ (GRU) Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 20)          1380      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 20)          2520      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 10)          210       \n",
      "=================================================================\n",
      "Total params: 4,110\n",
      "Trainable params: 4,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]), \n",
    "    tf.keras.layers.GRU(20, return_sequences=True), \n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 4ms/step - loss: 0.0489 - last_time_step_mse: 0.0388\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0295 - last_time_step_mse: 0.0155\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0241 - last_time_step_mse: 0.0097\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0206 - last_time_step_mse: 0.0068\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0189 - last_time_step_mse: 0.0058\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0179 - last_time_step_mse: 0.0052\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0172 - last_time_step_mse: 0.0049\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0167 - last_time_step_mse: 0.0047\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0163 - last_time_step_mse: 0.0045\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0158 - last_time_step_mse: 0.0042\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0157 - last_time_step_mse: 0.0042\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0155 - last_time_step_mse: 0.0041\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0151 - last_time_step_mse: 0.0039\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0150 - last_time_step_mse: 0.0038\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0149 - last_time_step_mse: 0.0039\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0148 - last_time_step_mse: 0.0038\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0144 - last_time_step_mse: 0.0035\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0144 - last_time_step_mse: 0.0036\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0143 - last_time_step_mse: 0.0035\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0141 - last_time_step_mse: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147f5d9192b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=[last_time_step_mse])\n",
    "model.fit(X_train, Y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 2ms/step - loss: 0.0143 - last_time_step_mse: 0.0039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01425903383642435, 0.003919767681509256]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [GRUs](https://youtu.be/MsxFDuYlTuQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/RNN12.png\" align=\"center\" width=\"500\"/>\n",
    "<img src=\"images/RNN13.png\" align=\"center\" width=\"500\"/>\n",
    "<img src=\"images/RNN14.png\" align=\"center\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/RNN15.png\" align=\"center\" width=\"500\"/>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f513c44cab0e7f43b93feb2c493bf956de6913ea868a31988c642fe6813eee3c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
